{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dade82a4-78b8-4e96-8115-b9f0b0cd6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def96585-d354-4550-9b01-3368d0b3aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54d3ccd-9348-4d2e-94e9-ecd23fdf1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43638bf-391d-4e5a-b9ba-eb4b1d825cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install absl-py nltk rouge-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab7d99d-bfed-4b95-a108-7ba4f2a72481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytorch-lightning in /home/goodone/.local/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: requests in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (59.6.0)\n",
      "Requirement already satisfied: filelock in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (2.0.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/goodone/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lightning) (3.27.9)\n",
      "Requirement already satisfied: lit in /home/goodone/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lightning) (17.0.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/goodone/.local/lib/python3.8/site-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/goodone/.local/lib/python3.8/site-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2342a3a3-1fa5-4f99-8d3f-bf453641d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303ca632-5f8b-48e7-bbfb-890f6edfe755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['medical_history', 'ground_truth_summary'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c9a02e2-332b-495f-95ed-8fd866157dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Admission Date: [ 2132-12-10 ] Discharge Date: [ 2132-12-14 ]\\n\\nDate of Birth: [ 2057-1-10 ] Sex: M\\n\\nService: MEDICINE\\n\\nCHIEF COMPLAINT: Respiratory distress\\n\\nPAST MEDICAL HISTORY: Hypertension, narrow-angle glaucoma,\\ndysthymia, laryngeal cancer status post XRT in [ 2115 ],\\nbilateral cataracts, history of testicular cancer status post\\norchiectomy bilaterally, gastroesophageal reflux disease,\\nperipheral vascular disease with femoral bypass of the right\\nto the left, status post carotid endarterectomy in [ 2128 ],\\nanemia with a negative esophagogastroduodenoscopy and\\ncolonoscopy workup, slight vocal cord paralysis, status post\\nprostatectomy after prostate cancer, 3 cm abdominal aortic\\naneurysm. His\\nneck with post-radiation changes. Cardiovascular: Regular\\nrate and rhythm, no murmurs. His lungs are clear to\\nauscultation bilaterally. Calcium 9.7, phosphorus 4.7. Arterial blood\\ngas was 7.36/42/52 on room air, and then increased to\\n7.35/47/185 on 100% non-rebreather. His chest x-ray at [ Hospital1 190 ] showed vascular engorgement on the right. A\\nrepeat after intubation shows proper tube placement with\\nslight increase in vascular engorgement on the right vs\\natelectasis. His electrocardiogram on admission was normal\\nsinus rhythm at 100, normal axis, left atrial enlargement,\\nintraventricular conduction delay more pronounced, ST\\ndepression, minimal on V4, V5, V6.\\n\\nHOSPITAL COURSE: The patient was admitted to the Intensive\\nCare Unit, given his respiratory distress. The patient was\\nplaced on Levaquin and Flagyl. The patient was changed to\\nclindamycin intravenously. Acid fast bacilli was negative.\\nMycology is pending. His blood\\npressure was more stabilized. He was extubated after one day\\nwithout complication. He had a right subclavian line\\nwhich was subsequently discontinued. He\\ndesaturated slightly to 92% while ambulating. However, the\\npatient was asymptomatic. Thus far his urine culture and blood cultures are no\\ngrowth to date. It was felt that the patient was stable for\\ndischarge to home rather than transfer back to the VA. He\\nshould follow up with the pulmonologists at [ Location 1268 ] for\\nfurther evaluation. At present, he has no cough or symptoms\\nconsistent with tuberculosis, and had a negative acid fast\\nbacilli during lavage.\\n\\nDISCHARGE DIAGNOSIS:\\n1. Aspiration pneumonia\\n\\nDISCHARGE MEDICATIONS: The patient is to continue all of his\\noutpatient medications, and take clindamycin 300 mg by mouth\\nevery six hours for seven additional days, for a total of a\\nten day course.\\n\\n\\n\\n\\n [ Name6 (MD) ] [ Name8 (MD) ], M.D. Since the previous tracing of [ 2132-12-10 ] the rate has slowed. There is\\n minimal apical pleural thickening. The costophrenic angles are sharp. The\\n visualized bones are otherwise unremarkable.\\n\\n IMPRESSION: No radiographic evidence of acute cardiopulmonary disease.\\n\\n [ 2132-12-10 ] 10:45 PM\\n CHEST (PORTABLE AP) Clip # [ Clip Number (Radiology) 80510 ]\\n Reason: please eval for pneumothorax, placement of subclavian\\n ______________________________________________________________________________\\n [ Hospital 4 ] MEDICAL CONDITION:\\n 75 year old man with acute resp distress, intubated\\n REASON FOR THIS EXAMINATION:\\n please eval for pneumothorax, placement of subclavian\\n ______________________________________________________________________________\\n FINAL REPORT\\n INDICATION: Acute respiratory distress, intubated, evaluate for pneumothorax.\\n Check subclavian line placement.\\n\\n A single frontal chest radiograph dated [ 2132-12-10 ] at 22:54 is compared\\n with prior chest radiograph obtained 4 hours earlier. The ET tube is\\n terminating at the thoracic inlet, unchanged in position. A right subclavian\\n catheter is terminating in the SVC. Left\\n lower lobe opacities appear similar allowing for differences in technique.\\n There are small bilateral pleural effusions.\\n\\n IMPRESSION:\\n\\n 1. Worsening opacity in right lower lobe. Given history of recent bronch,\\n this could be due to lavage fluid but other process is also possible such as\\n aspiration or pneumonia.\\n\\n 2. Small bilateral pleural effusions.\\n\\n 3. No significant change in left lower lobe opacity allowing for incomplete\\n imaging of the left lung laterally.\\n\\n [ 2132-12-10 ] 6:34 PM\\n CHEST (PORTABLE AP) Clip # [ Clip Number (Radiology) 80509 ]\\n Reason: s/p intubation\\n ______________________________________________________________________________\\n [ Hospital 4 ] MEDICAL CONDITION:\\n 75 year old man with above.\\n REASON FOR THIS EXAMINATION:\\n s/p intubation\\n ______________________________________________________________________________\\n FINAL REPORT\\n INDICATION: S/P intubation.\\n\\n AP chest dated [ 2132-12-10 ] at 18:42 is compared with the AP chest dated [ 2132-12-10 ]\\n at 16:31.\\n\\n There has been interval placement of an ET tube. The tip of the tube is in\\n satisfactory position. There has been no\\n significant change in the appearance of the lungs. There is faint\\n reticulonodular opacity at the right lung base. There is no pneumothorax.\\n\\n Again demonstrated are healed left lateral rib fractures.\\n\\n IMPRESSION:\\n 1. The NG tube side hole is located in the distal esophagus.\\n 2. The ET tube is in satisfactory postion.\\n\\n [ 2132-12-10 ] 6:09 PM\\n CTA CHEST W&W/O C &RECONS; CT 100CC NON IONIC CONTRAST Clip # [ Clip Number (Radiology) 80508 ]\\n Reason: Assess for PE.\\n Field of view: 39 Contrast: OPTIRAY Amt: 100\\n ______________________________________________________________________________\\n [ Hospital 4 ] MEDICAL CONDITION:\\n 75 year old man with large smoking history, history of laryngeal CA with\\n suspicion for recurrance v new lung primary who is hypoxic.\\n REASON FOR THIS EXAMINATION:\\n Assess for PE.\\n No contraindications for IV contrast\\n ______________________________________________________________________________\\n WET READ: DKKD WED [ 2132-12-10 ] 9:32 PM\\n no gross pe; patchy lung opacites\\n ______________________________________________________________________________\\n FINAL REPORT ABNORMAL!\\n HISTORY: 75 year old man with smoking history and laryngeal cancer who is\\n hypoxic, assess for PE.\\n\\n TECHNIQUE: Multiple axial images were obtained from the chest with IV\\n contrast, along with reconstructed images.\\n\\n CONTRAST: 100 cc Optiray administered secondary to fast rate of bolus\\n injection.\\n\\n CT OF THE CHEST WITH IV CONTRAST: The heart and pericardium are unremarkable.\\n There are no gross filling defects seen in the pulmonary arteries to the\\n segmental levels. There are patchy areas of opacity seen in the apices, right\\n upper lobe and lower lobes, which findings are consistent with possible\\n multifocal pneumonia or aspiration. There is no significant axillary lymphadenopathy. The trachea and the\\n major airways are patent.\\n\\n BONE WINDOWS: There are degenerative changes seen but there are no suspicious\\n lytic or sclerotic lesions.\\n\\n IMPRESSION:\\n\\n 1) No gross pulmonary embolus.\\n\\n 2) Bilateral lower lobe and bilateral apical opacities consistent with\\n multifocal pneumonia or aspiration.\\n\\n NURSING MICU NOTE 7P-7A\\nPT ADMITTED TO MICU AT 2045 FROM ED S/P ELECTIVE INTUBATION DUE TACHYPNEA AND POOR O2 SATURATION. PT W/ WORSENING PN. PT WAS RESTLESS, BUCKING VENT. CURRENTLY PROPOFOL GTT AT 10MCG/KG/MIN W/ GOOD EFFECT.\\n\\nRESP: INTIAL VENT SETTINGS AC 600X12 PEEP5 100%. ABG 7.34/42/347. PT SUCTIONED FOR MODERATE AMT THICK TAN BLOOD TINGE SECREATIONS. PT STARTED ON LEVOFLOXACIN AND FLAGYL. IVF D5 1/2 NS AT 100CC/HR. UA C&S SENT.\\n\\nACCESS: PT HAS [ Name (NI) 185 ] #24 IN LEFT HAND FROM OSH. [ Name (NI) 185 ] #20 IN RIGHT LOWER ARM. NOT ABLE TO GET IN CONTACT W/ FAMILY. NO PHONE NUMBER IN PT'S PERSONAL BELONGS. TEAM WILL NEED TO GET IN CONTACT W/ PT'S FAMILY TODAY. PT IS A FULL CODE IN MICU.\\n MICU Nursing Progress Note\\nVery pleasant and cooperative male admitted from JP VA last evening p becoming hypoxic post bronchoscopy. WR VA on diversion.\\n\\nNeuro- Easily arrousable on Propofol @10mcg/k/m; d/c'd @ 11:30am for extubation. FC, MAE, PERLA, grasp, push = bilat. BS diminished r base, clear all other zones. Cough and incentive spiromenty q1-3h for thick tan secretion/plugs.\\n\\nCV-130-158/45-55, HR 70's SR no vea. total I/O 0000-1700= 2435/1420. Levo and flagyl d/c'd --Clinda IV q8h start 1400.\\n\\nGI- NPO post bronch and while intubated. tolerated clear liqs very easily this pm. Pt status and plan explained in detail to pt and wife. ABLE TO TRANSFER WELL BACK TO BED WITH ONE ASSIST. TAKING DEEP BREATHS AND COUGH ONLY WHEN REMINDED TO DO SO. PT SLEPT WELL THROUGHOUT THE NIGHT MAINTAINING O2SAT'S IN THE HIGH 90'S. TEMP 99.5MAX THROUGHOUT THE NIGHT.\\nHEMODYNAMICLLY STABLE. Vital signs have been stable; NSR,no ectopy. BP stable 130s to 150s/40s. Cool mist mask changed this morning to NC, 2L with sats remaining mid to high 90s. Patient on aspiration precautions and diet is honey thickened liquids. Patient had excellent intake at breakfast and lunch.\n"
     ]
    }
   ],
   "source": [
    "with open('2.txt', 'r') as file:\n",
    "    text_1 = file.read()\n",
    "print(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb04210-a723-423f-895f-875a8d5b36f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 75-year-old male with\n",
      "a large tobacco history, history of laryngeal cancer status\n",
      "post XRT in [**2124**], who was recently admitted to [**Location 1268**]\n",
      "VA for workup for six weeks of progressive dyspnea.  Workup\n",
      "at that time included treatment of pneumonia and anemia.\n",
      "Exercise stress test at that time was positive for inferior\n",
      "defect, but thought by Cardiology to be insignificant.  His\n",
      "chest CT was notable for slightly increased pulmonary\n",
      "opacities in the right middle lobe and right upper lobe.  The\n",
      "patient was then bronchoscoped at [**Location (un) 538**] VA with 180\n",
      "cc of saline infused for bronchoalveolar lavage, with only 60\n",
      "cc received by suctioning back.  His airways were otherwise\n",
      "normal.  The patient developed hypoxemia during the\n",
      "bronchoscopy.  His post-bronchoscopy course was complicated\n",
      "by tachypnea and poor oxygen saturation of 80% on room air.\n",
      "He was transferred to [**Hospital1 69**]\n",
      "and, after one to two hours of continued respiratory distress\n",
      "and an episode of emesis, the patient was intubated\n",
      "electively for fear of impending respiratory failure and\n",
      "aspiration.\n",
      "\n",
      "REVIEW OF SYSTEMS:  Negative for chest pain, positive for\n",
      "shortness of breath, negative fever and chills, negative\n",
      "changes in vision or hearing, positive cough, no\n",
      "palpitations, no changes in bowel movements, no changes in\n",
      "urine, no back pain, rash or headache.\n"
     ]
    }
   ],
   "source": [
    "summary_1 = df['ground_truth_summary'].iloc[1]\n",
    "print(summary_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527f7739-4f7f-43ed-a426-ed94bd157e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = df[:50]\n",
    "text_len = []\n",
    "summary_len=[]\n",
    "for i in range(len(example_data)):\n",
    "    text_example = example_data['medical_history'].iloc[i]\n",
    "    text_example = text_example.replace('\\n','')\n",
    "    text_words = text_example.split()\n",
    "    text_len.append(len(text_words))\n",
    "    summary_example = example_data['ground_truth_summary'].iloc[i]\n",
    "    summary_example = summary_example.replace('\\n','')\n",
    "    summary_words = summary_example.split()\n",
    "    summary_len.append(len(summary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667b8175-ddb1-41d1-a3da-3b5467907863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(text_len)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0270b6bb-1a10-4788-a72c-7af5b16ced5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class abstractive_summ(Dataset):\n",
    "    def __init__(self, tokenizer, file_path, num_samples, input_length, output_length, print_text=False):         \n",
    "        self.dataset =  pd.read_csv(file_path)\n",
    "        if num_samples:\n",
    "            self.dataset = self.dataset[:num_samples]\n",
    "        self.input_length = input_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_length = output_length\n",
    "        self.print_text = print_text\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.replace('\\n','')\n",
    "        text = text.replace('``', '')\n",
    "        text = text.replace('\"', '')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def convert_to_features(self, example_batch):\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "        \n",
    "        if self.print_text:\n",
    "            print(\"Input Text: \", self.clean_text(example_batch['medical_history']))\n",
    "#         input_ = self.clean_text(example_batch['text']) + \" </s>\"\n",
    "#         target_ = self.clean_text(example_batch['headline']) + \" </s>\"\n",
    "        \n",
    "        input_ = self.clean_text(example_batch['medical_history'])\n",
    "        target_ = self.clean_text(example_batch['ground_truth_summary'])\n",
    "        \n",
    "        source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "       \n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source, targets = self.convert_to_features(self.dataset.iloc[index])\n",
    "        \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fed9d4ea-6469-4ff9-8a65-7a5e6ac2fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, num_samples, args):\n",
    "    file_path = f\"{type_path}_data.csv\"  # train_data.csv, validation_data.csv, test_data.csv\n",
    "    dataset = abstractive_summ(tokenizer=tokenizer, file_path=file_path, num_samples=num_samples, input_length=args.max_input_length, output_length=args.max_output_length)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "130556a5-55ec-4dd5-9c2c-eab6a4c9da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from datasets import load_metric\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "        self.rouge_metric = load_metric('rouge') \n",
    "        \n",
    "        if self.hparams.freeze_embeds:\n",
    "            self.freeze_embeds()\n",
    "        if self.hparams.freeze_encoder:\n",
    "            self.freeze_params(self.model.get_encoder())\n",
    "            assert_all_frozen(self.model.get_encoder())\n",
    "            \n",
    "        self.n_obs = {\n",
    "            \"train\": self.hparams.n_train,\n",
    "            \"validation\": self.hparams.n_val,\n",
    "            \"test\": self.hparams.n_test\n",
    "        }\n",
    "        \n",
    "    def freeze_params(self, model):\n",
    "        for par in model.parameters():\n",
    "            par.requires_grad = False\n",
    "            \n",
    "    def freeze_embeds(self):\n",
    "        try:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "        except AttributeError:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "  \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.hparams.total_steps\n",
    "        )\n",
    "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]\n",
    "\n",
    "    def train_dataloader(self):   \n",
    "        train_dataset = get_dataset(self.tokenizer, 'train', self.n_obs['train'], self.hparams)\n",
    "        return DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        validation_dataset = get_dataset(self.tokenizer, 'validation', self.n_obs['validation'], self.hparams)\n",
    "        return DataLoader(validation_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = get_dataset(self.tokenizer, 'test', self.n_obs['test'], self.hparams)\n",
    "        return DataLoader(test_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5efb9bd2-25d5-4bc2-a565-8e6e0124c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args_dict = {\n",
    "    'model_name_or_path': 't5-small',\n",
    "    'tokenizer_name_or_path': 't5-small',\n",
    "    'max_input_length': 512,\n",
    "    'max_output_length': 128,\n",
    "    'freeze_encoder': False,\n",
    "    'freeze_embeds': False,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_steps': 0,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'num_train_epochs': 3,\n",
    "    'n_train': 2000,  #training samples\n",
    "    'n_val': 400,     # validation samples\n",
    "    'n_test': 400,    #test samples\n",
    "    'gradient_accumulation_steps': 16,\n",
    "    'n_gpu': 1,\n",
    "    'early_stop_callback': False,\n",
    "    'fp_16': False,  \n",
    "    'opt_level': 'O1', \n",
    "    'max_grad_norm': 1.0,\n",
    "    'seed': 42,\n",
    "    #'total_steps': (n_train / train_batch_size / gradient_accumulation_steps) * num_train_epochs\n",
    "    'total_steps': 23\n",
    "}\n",
    "args = Namespace(**args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "841dab8e-f47f-4769-933b-f88d47493d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca765761-672a-4c13-ad7c-19c830d259d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.num_train_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48063a-2f6e-406d-ad7c-b4b7b8180496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/goodone/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379cdbc6c0a24244988d4d56a263c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ace75c-f15f-4323-802a-b6bfe8af971f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
