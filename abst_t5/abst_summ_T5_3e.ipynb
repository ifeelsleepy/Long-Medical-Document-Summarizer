{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dade82a4-78b8-4e96-8115-b9f0b0cd6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def96585-d354-4550-9b01-3368d0b3aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54d3ccd-9348-4d2e-94e9-ecd23fdf1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43638bf-391d-4e5a-b9ba-eb4b1d825cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install absl-py nltk rouge-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab7d99d-bfed-4b95-a108-7ba4f2a72481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytorch-lightning in /home/goodone/.local/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.12.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2023.10.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (4.8.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/goodone/.local/lib/python3.8/site-packages (from pytorch-lightning) (0.10.0)\n",
      "Requirement already satisfied: requests in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/goodone/.local/lib/python3.8/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (59.6.0)\n",
      "Requirement already satisfied: filelock in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/goodone/.local/lib/python3.8/site-packages (from torch>=1.12.0->pytorch-lightning) (2.0.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12.0->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/goodone/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lightning) (3.27.9)\n",
      "Requirement already satisfied: lit in /home/goodone/.local/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lightning) (17.0.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/goodone/.local/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/goodone/.local/lib/python3.8/site-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/goodone/.local/lib/python3.8/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/goodone/.local/lib/python3.8/site-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2342a3a3-1fa5-4f99-8d3f-bf453641d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ext_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303ca632-5f8b-48e7-bbfb-890f6edfe755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['medical_history', 'ground_truth_summary'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527f7739-4f7f-43ed-a426-ed94bd157e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = df[:50]\n",
    "text_len = []\n",
    "summary_len=[]\n",
    "for i in range(len(example_data)):\n",
    "    text_example = example_data['medical_history'].iloc[i]\n",
    "    text_example = text_example.replace('\\n','')\n",
    "    text_words = text_example.split()\n",
    "    text_len.append(len(text_words))\n",
    "    summary_example = example_data['ground_truth_summary'].iloc[i]\n",
    "    summary_example = summary_example.replace('\\n','')\n",
    "    summary_words = summary_example.split()\n",
    "    summary_len.append(len(summary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667b8175-ddb1-41d1-a3da-3b5467907863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAepklEQVR4nO3de5CV5X3A8d9y2QUqu4DALhsXBFGocklDlGw11BSGSxyrCdOqcTpoM1gtZGpIvJAakbYzWNtJbTOEdKYNNDNRqh3B1gutgkBNgRQqQaKhQrFgZDHBsAsoK7JP/2A48chFF3ef5ayfz8yZ4bzvs+c85+E9Z79zLnvKUkopAAAy6dLREwAAPl7EBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZNWtoyfwfi0tLfH6669H7969o6ysrKOnAwB8CCmlOHDgQNTW1kaXLqd/buOsi4/XX3896urqOnoaAMAZ2L17d5x33nmnHXPWxUfv3r0j4tjkKysrO3g2AMCH0dTUFHV1dYXf46dz1sXH8ZdaKisrxQcAlJgP85YJbzgFALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFatio8FCxbEpZdeGr17946BAwfGtddeG9u2bSsac+WVV0ZZWVnR6dZbb23TSQMApatV8bFmzZqYNWtWrF+/Pp555pk4cuRITJ48OQ4dOlQ0bubMmbFnz57C6YEHHmjTSQMApatVXyy3YsWKovNLliyJgQMHxqZNm2LChAmF7b169Yqampq2mSEA0Kl8pPd8NDY2RkREv379irb/4Ac/iP79+8eoUaNi7ty58dZbb53yMpqbm6OpqanoBAB0Xq165uO9Wlpa4vbbb4/LL788Ro0aVdj+pS99KYYMGRK1tbWxZcuWuOuuu2Lbtm3x2GOPnfRyFixYEPPnzz/TabTa+Xc/me262sqr91/V0VMAgDZTllJKZ/KDt912Wzz99NPx/PPPx3nnnXfKcatWrYqJEyfG9u3b44ILLjhhf3NzczQ3NxfONzU1RV1dXTQ2NkZlZeWZTO20xAcAtL2mpqaoqqr6UL+/z+iZj9mzZ8cTTzwRa9euPW14RESMHz8+IuKU8VFRUREVFRVnMg0AoAS1Kj5SSvGVr3wlli1bFqtXr46hQ4d+4M9s3rw5IiIGDRp0RhMEADqXVsXHrFmz4qGHHorHH388evfuHQ0NDRERUVVVFT179owdO3bEQw89FJ///Ofj3HPPjS1btsRXv/rVmDBhQowZM6ZdbgAAUFpaFR+LFi2KiGN/SOy9Fi9eHDfddFOUl5fHs88+Gw8++GAcOnQo6urqYvr06XHPPfe02YQBgNLW6pddTqeuri7WrFnzkSYEAHRuvtsFAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgq1bFx4IFC+LSSy+N3r17x8CBA+Paa6+Nbdu2FY05fPhwzJo1K84999w455xzYvr06bF37942nTQAULpaFR9r1qyJWbNmxfr16+OZZ56JI0eOxOTJk+PQoUOFMV/96lfjX//1X+PRRx+NNWvWxOuvvx5f/OIX23ziAEBp6taawStWrCg6v2TJkhg4cGBs2rQpJkyYEI2NjfEP//AP8dBDD8Vv//ZvR0TE4sWL49d//ddj/fr18ZnPfKbtZg4AlKSP9J6PxsbGiIjo169fRERs2rQpjhw5EpMmTSqMGTlyZAwePDjWrVv3Ua4KAOgkWvXMx3u1tLTE7bffHpdffnmMGjUqIiIaGhqivLw8+vTpUzS2uro6GhoaTno5zc3N0dzcXDjf1NR0plMCAErAGT/zMWvWrNi6dWssXbr0I01gwYIFUVVVVTjV1dV9pMsDAM5uZxQfs2fPjieeeCKee+65OO+88wrba2pq4p133on9+/cXjd+7d2/U1NSc9LLmzp0bjY2NhdPu3bvPZEoAQIloVXyklGL27NmxbNmyWLVqVQwdOrRo/7hx46J79+6xcuXKwrZt27bFrl27or6+/qSXWVFREZWVlUUnAKDzatV7PmbNmhUPPfRQPP7449G7d+/C+ziqqqqiZ8+eUVVVFV/+8pdjzpw50a9fv6isrIyvfOUrUV9f75MuAEBEtDI+Fi1aFBERV155ZdH2xYsXx0033RQREX/9138dXbp0ienTp0dzc3NMmTIlvvOd77TJZAGA0teq+EgpfeCYHj16xMKFC2PhwoVnPCkAoPPy3S4AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AIKtWx8fatWvj6quvjtra2igrK4vly5cX7b/pppuirKys6DR16tS2mi8AUOJaHR+HDh2KsWPHxsKFC085ZurUqbFnz57C6eGHH/5IkwQAOo9urf2BadOmxbRp0047pqKiImpqas54UgBA59Uu7/lYvXp1DBw4MEaMGBG33XZb7Nu375Rjm5ubo6mpqegEAHRebR4fU6dOje9///uxcuXK+Iu/+ItYs2ZNTJs2LY4ePXrS8QsWLIiqqqrCqa6urq2nBACcRVr9sssHuf766wv/Hj16dIwZMyYuuOCCWL16dUycOPGE8XPnzo05c+YUzjc1NQkQAOjE2v2jtsOGDYv+/fvH9u3bT7q/oqIiKisri04AQOfV7vHx2muvxb59+2LQoEHtfVUAQAlo9csuBw8eLHoWY+fOnbF58+bo169f9OvXL+bPnx/Tp0+Pmpqa2LFjR9x5550xfPjwmDJlSptOHAAoTa2Oj40bN8bnPve5wvnj79eYMWNGLFq0KLZs2RL/+I//GPv374/a2tqYPHly/Nmf/VlUVFS03awBgJLV6vi48sorI6V0yv3/9m//9pEmBAB0br7bBQDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AIKtWx8fatWvj6quvjtra2igrK4vly5cX7U8pxb333huDBg2Knj17xqRJk+KVV15pq/kCACWu1fFx6NChGDt2bCxcuPCk+x944IH427/92/jud78bGzZsiF/7tV+LKVOmxOHDhz/yZAGA0tettT8wbdq0mDZt2kn3pZTiwQcfjHvuuSeuueaaiIj4/ve/H9XV1bF8+fK4/vrrP9psAYCS16bv+di5c2c0NDTEpEmTCtuqqqpi/PjxsW7dupP+THNzczQ1NRWdAIDOq03jo6GhISIiqquri7ZXV1cX9r3fggULoqqqqnCqq6tryykBAGeZDv+0y9y5c6OxsbFw2r17d0dPCQBoR20aHzU1NRERsXfv3qLte/fuLex7v4qKiqisrCw6AQCdV5vGx9ChQ6OmpiZWrlxZ2NbU1BQbNmyI+vr6trwqAKBEtfrTLgcPHozt27cXzu/cuTM2b94c/fr1i8GDB8ftt98ef/7nfx4XXnhhDB06NL75zW9GbW1tXHvttW05bwCgRLU6PjZu3Bif+9znCufnzJkTEREzZsyIJUuWxJ133hmHDh2KW265Jfbv3x9XXHFFrFixInr06NF2swYASlZZSil19CTeq6mpKaqqqqKxsbFd3v9x/t1PtvlltrdX77+qo6cAAKfVmt/fHf5pFwDg40V8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZdevoCfDBzr/7yY6eQqu9ev9VHT0FAM5SnvkAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyavP4uO+++6KsrKzoNHLkyLa+GgCgRLXLn1e/5JJL4tlnn/3VlXTzV9wBgGPapQq6desWNTU17XHRAECJa5f3fLzyyitRW1sbw4YNixtvvDF27dp1yrHNzc3R1NRUdAIAOq+ylFJqywt8+umn4+DBgzFixIjYs2dPzJ8/P372s5/F1q1bo3fv3ieMv++++2L+/PknbG9sbIzKysq2nFpElOY3xJJHKX4Tbykez6W4zsAHa2pqiqqqqg/1+7vNn/mYNm1a/O7v/m6MGTMmpkyZEk899VTs378/HnnkkZOOnzt3bjQ2NhZOu3fvbuspAQBnkXZ/J2ifPn3ioosuiu3bt590f0VFRVRUVLT3NACAs0S7/52PgwcPxo4dO2LQoEHtfVUAQAlo8/j4+te/HmvWrIlXX301/vM//zO+8IUvRNeuXeOGG25o66sCAEpQm7/s8tprr8UNN9wQ+/btiwEDBsQVV1wR69evjwEDBrT1VQEAJajN42Pp0qVtfZEAQCfiu10AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACCrdv9uFygVpfgNsQClyDMfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZdevoCQDAceff/WRHT+Fj4dX7r+rQ6/fMBwCQlfgAALISHwBAVuIDAMhKfAAAWYkPACAr8QEAZCU+AICsxAcAkJX4AACyEh8AQFbiAwDISnwAAFn5VluATso3xHK28swHAJCV+AAAshIfAEBW4gMAyEp8AABZiQ8AICvxAQBkJT4AgKzEBwCQVbvFx8KFC+P888+PHj16xPjx4+NHP/pRe10VAFBC2iU+/umf/inmzJkT8+bNi//+7/+OsWPHxpQpU+KNN95oj6sDAEpIu8THt771rZg5c2bcfPPNcfHFF8d3v/vd6NWrV3zve99rj6sDAEpIm3+x3DvvvBObNm2KuXPnFrZ16dIlJk2aFOvWrTthfHNzczQ3NxfONzY2RkREU1NTW08tIiJamt9ql8sFPpz2um9zIo93nEp73A+PX2ZK6QPHtnl8/OIXv4ijR49GdXV10fbq6ur46U9/esL4BQsWxPz580/YXldX19ZTA84CVQ929AyA9rwfHjhwIKqqqk47ps3jo7Xmzp0bc+bMKZxvaWmJN998M84999woKys75c81NTVFXV1d7N69OyorK3NM9axlLY6xDsdYh1+xFsdYh1+xFse0xzqklOLAgQNRW1v7gWPbPD769+8fXbt2jb179xZt37t3b9TU1JwwvqKiIioqKoq29enT50NfX2Vl5cf6AHova3GMdTjGOvyKtTjGOvyKtTimrdfhg57xOK7N33BaXl4e48aNi5UrVxa2tbS0xMqVK6O+vr6trw4AKDHt8rLLnDlzYsaMGfHpT386LrvssnjwwQfj0KFDcfPNN7fH1QEAJaRd4uO6666Ln//853HvvfdGQ0NDfPKTn4wVK1ac8CbUj6KioiLmzZt3wks2H0fW4hjrcIx1+BVrcYx1+BVrcUxHr0NZ+jCfiQEAaCO+2wUAyEp8AABZiQ8AICvxAQBkVbLxsXDhwjj//POjR48eMX78+PjRj37U0VM6Y/fdd1+UlZUVnUaOHFnYf/jw4Zg1a1ace+65cc4558T06dNP+CNuu3btiquuuip69eoVAwcOjDvuuCPefffdojGrV6+OT33qU1FRURHDhw+PJUuW5Lh5p7V27dq4+uqro7a2NsrKymL58uVF+1NKce+998agQYOiZ8+eMWnSpHjllVeKxrz55ptx4403RmVlZfTp0ye+/OUvx8GDB4vGbNmyJT772c9Gjx49oq6uLh544IET5vLoo4/GyJEjo0ePHjF69Oh46qmn2vz2nsoHrcNNN910wjEyderUojGdYR0WLFgQl156afTu3TsGDhwY1157bWzbtq1oTM77Q0c9znyYdbjyyitPOCZuvfXWojGlvg4REYsWLYoxY8YU/hhWfX19PP3004X9H4fjIeKD16HkjodUgpYuXZrKy8vT9773vfSTn/wkzZw5M/Xp0yft3bu3o6d2RubNm5cuueSStGfPnsLp5z//eWH/rbfemurq6tLKlSvTxo0b02c+85n0m7/5m4X97777bho1alSaNGlSeuGFF9JTTz2V+vfvn+bOnVsY87//+7+pV69eac6cOemll15K3/72t1PXrl3TihUrst7W93vqqafSn/zJn6THHnssRURatmxZ0f77778/VVVVpeXLl6cf//jH6Xd+53fS0KFD09tvv10YM3Xq1DR27Ni0fv369B//8R9p+PDh6YYbbijsb2xsTNXV1enGG29MW7duTQ8//HDq2bNn+ru/+7vCmB/+8Iepa9eu6YEHHkgvvfRSuueee1L37t3Tiy++2O5rkNIHr8OMGTPS1KlTi46RN998s2hMZ1iHKVOmpMWLF6etW7emzZs3p89//vNp8ODB6eDBg4Uxue4PHfk482HW4bd+67fSzJkzi46JxsbGTrUOKaX0L//yL+nJJ59M//M//5O2bduWvvGNb6Tu3bunrVu3ppQ+HsfDh1mHUjseSjI+LrvssjRr1qzC+aNHj6ba2tq0YMGCDpzVmZs3b14aO3bsSfft378/de/ePT366KOFbS+//HKKiLRu3bqU0rFfXF26dEkNDQ2FMYsWLUqVlZWpubk5pZTSnXfemS655JKiy77uuuvSlClT2vjWnLn3/9JtaWlJNTU16S//8i8L2/bv358qKirSww8/nFJK6aWXXkoRkf7rv/6rMObpp59OZWVl6Wc/+1lKKaXvfOc7qW/fvoW1SCmlu+66K40YMaJw/vd+7/fSVVddVTSf8ePHpz/8wz9s09v4YZwqPq655ppT/kxnXIeUUnrjjTdSRKQ1a9aklPLeH86mx5n3r0NKx37Z/PEf//Epf6YzrsNxffv2TX//93//sT0ejju+DimV3vFQci+7vPPOO7Fp06aYNGlSYVuXLl1i0qRJsW7dug6c2UfzyiuvRG1tbQwbNixuvPHG2LVrV0REbNq0KY4cOVJ0e0eOHBmDBw8u3N5169bF6NGji/6I25QpU6KpqSl+8pOfFMa89zKOjzmb12znzp3R0NBQNO+qqqoYP3580W3v06dPfPrTny6MmTRpUnTp0iU2bNhQGDNhwoQoLy8vjJkyZUps27YtfvnLXxbGnO3rs3r16hg4cGCMGDEibrvttti3b19hX2ddh8bGxoiI6NevX0Tkuz+cbY8z71+H437wgx9E//79Y9SoUTF37tx46623Cvs64zocPXo0li5dGocOHYr6+vqP7fHw/nU4rpSOhw7/VtvW+sUvfhFHjx494a+lVldXx09/+tMOmtVHM378+FiyZEmMGDEi9uzZE/Pnz4/PfvazsXXr1mhoaIjy8vITvmyvuro6GhoaIiKioaHhpOtxfN/pxjQ1NcXbb78dPXv2bKdbd+aOz/1k837v7Ro4cGDR/m7dukW/fv2KxgwdOvSEyzi+r2/fvqdcn+OX0dGmTp0aX/ziF2Po0KGxY8eO+MY3vhHTpk2LdevWRdeuXTvlOrS0tMTtt98el19+eYwaNaowzxz3h1/+8pdnzePMydYhIuJLX/pSDBkyJGpra2PLli1x1113xbZt2+Kxxx6LiM61Di+++GLU19fH4cOH45xzzolly5bFxRdfHJs3b/5YHQ+nWoeI0jseSi4+OqNp06YV/j1mzJgYP358DBkyJB555JGzMgrI7/rrry/8e/To0TFmzJi44IILYvXq1TFx4sQOnFn7mTVrVmzdujWef/75jp5KhzrVOtxyyy2Ff48ePToGDRoUEydOjB07dsQFF1yQe5rtasSIEbF58+ZobGyMf/7nf44ZM2bEmjVrOnpa2Z1qHS6++OKSOx5K7mWX/v37R9euXU94N/PevXujpqamg2bVtvr06RMXXXRRbN++PWpqauKdd96J/fv3F4157+2tqak56Xoc33e6MZWVlWdt4Byf++n+r2tqauKNN94o2v/uu+/Gm2++2Sbrc7YeU8OGDYv+/fvH9u3bI6LzrcPs2bPjiSeeiOeeey7OO++8wvZc94ez5XHmVOtwMuPHj4+IKDomOss6lJeXx/Dhw2PcuHGxYMGCGDt2bPzN3/zNx+54ONU6nMzZfjyUXHyUl5fHuHHjYuXKlYVtLS0tsXLlyqLXvkrZwYMHY8eOHTFo0KAYN25cdO/evej2btu2LXbt2lW4vfX19fHiiy8W/fJ55plnorKysvCUXH19fdFlHB9zNq/Z0KFDo6ampmjeTU1NsWHDhqLbvn///ti0aVNhzKpVq6KlpaVw56uvr4+1a9fGkSNHCmOeeeaZGDFiRPTt27cwppTW57XXXot9+/bFoEGDIqLzrENKKWbPnh3Lli2LVatWnfAyUa77Q0c/znzQOpzM5s2bIyKKjolSX4dTaWlpiebm5o/N8XAqx9fhZM7646FVb089SyxdujRVVFSkJUuWpJdeeindcsstqU+fPkXv4i0lX/va19Lq1avTzp070w9/+MM0adKk1L9///TGG2+klI59lGzw4MFp1apVaePGjam+vj7V19cXfv74R6gmT56cNm/enFasWJEGDBhw0o9Q3XHHHenll19OCxcuPCs+anvgwIH0wgsvpBdeeCFFRPrWt76VXnjhhfR///d/KaVjH7Xt06dPevzxx9OWLVvSNddcc9KP2v7Gb/xG2rBhQ3r++efThRdeWPQR0/3796fq6ur0+7//+2nr1q1p6dKlqVevXid8xLRbt27pr/7qr9LLL7+c5s2bl/UjpqdbhwMHDqSvf/3rad26dWnnzp3p2WefTZ/61KfShRdemA4fPtyp1uG2225LVVVVafXq1UUfGXzrrbcKY3LdHzryceaD1mH79u3pT//0T9PGjRvTzp070+OPP56GDRuWJkyY0KnWIaWU7r777rRmzZq0c+fOtGXLlnT33XensrKy9O///u8ppY/H8fBB61CKx0NJxkdKKX37299OgwcPTuXl5emyyy5L69ev7+gpnbHrrrsuDRo0KJWXl6dPfOIT6brrrkvbt28v7H/77bfTH/3RH6W+ffumXr16pS984Qtpz549RZfx6quvpmnTpqWePXum/v37p6997WvpyJEjRWOee+659MlPfjKVl5enYcOGpcWLF+e4eaf13HPPpYg44TRjxoyU0rGP237zm99M1dXVqaKiIk2cODFt27at6DL27duXbrjhhnTOOeekysrKdPPNN6cDBw4Ujfnxj3+crrjiilRRUZE+8YlPpPvvv/+EuTzyyCPpoosuSuXl5emSSy5JTz75ZLvd7vc73Tq89dZbafLkyWnAgAGpe/fuaciQIWnmzJkn3Nk7wzqcbA0iouhYzXl/6KjHmQ9ah127dqUJEyakfv36pYqKijR8+PB0xx13FP1dh5RKfx1SSukP/uAP0pAhQ1J5eXkaMGBAmjhxYiE8Uvp4HA8pnX4dSvF4KEsppdY9VwIAcOZK7j0fAEBpEx8AQFbiAwDISnwAAFmJDwAgK/EBAGQlPgCArMQHAJCV+AAAshIfAEBW4gMAyEp8AABZ/T+qJWs+NFh2QgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(text_len)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0270b6bb-1a10-4788-a72c-7af5b16ced5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class abstractive_summ(Dataset):\n",
    "    def __init__(self, tokenizer, file_path, num_samples, input_length, output_length, print_text=False):         \n",
    "        self.dataset =  pd.read_csv(file_path)\n",
    "        if num_samples:\n",
    "            self.dataset = self.dataset[:num_samples]\n",
    "        self.input_length = input_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_length = output_length\n",
    "        self.print_text = print_text\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.replace('\\n','')\n",
    "        text = text.replace('``', '')\n",
    "        text = text.replace('\"', '')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def convert_to_features(self, example_batch):\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "        \n",
    "        if self.print_text:\n",
    "            print(\"Input Text: \", self.clean_text(example_batch['medical_history']))\n",
    "#         input_ = self.clean_text(example_batch['text']) + \" </s>\"\n",
    "#         target_ = self.clean_text(example_batch['headline']) + \" </s>\"\n",
    "        \n",
    "        input_ = self.clean_text(example_batch['medical_history'])\n",
    "        target_ = self.clean_text(example_batch['ground_truth_summary'])\n",
    "        \n",
    "        source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "       \n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source, targets = self.convert_to_features(self.dataset.iloc[index])\n",
    "        \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fed9d4ea-6469-4ff9-8a65-7a5e6ac2fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, num_samples, args):\n",
    "    file_path = f\"{type_path}_data.csv\"  # train_data.csv, validation_data.csv, test_data.csv\n",
    "    dataset = abstractive_summ(tokenizer=tokenizer, file_path=file_path, num_samples=num_samples, input_length=args.max_input_length, output_length=args.max_output_length)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "130556a5-55ec-4dd5-9c2c-eab6a4c9da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "from datasets import load_metric\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "        self.rouge_metric = load_metric('rouge') \n",
    "        \n",
    "        if self.hparams.freeze_embeds:\n",
    "            self.freeze_embeds()\n",
    "        if self.hparams.freeze_encoder:\n",
    "            self.freeze_params(self.model.get_encoder())\n",
    "            assert_all_frozen(self.model.get_encoder())\n",
    "            \n",
    "        self.n_obs = {\n",
    "            \"train\": self.hparams.n_train,\n",
    "            \"validation\": self.hparams.n_val,\n",
    "            \"test\": self.hparams.n_test\n",
    "        }\n",
    "        \n",
    "    def freeze_params(self, model):\n",
    "        for par in model.parameters():\n",
    "            par.requires_grad = False\n",
    "            \n",
    "    def freeze_embeds(self):\n",
    "        try:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "        except AttributeError:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "  \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=self.hparams.total_steps\n",
    "        )\n",
    "        return [optimizer], [{'scheduler': scheduler, 'interval': 'step'}]\n",
    "\n",
    "    def train_dataloader(self):   \n",
    "        train_dataset = get_dataset(self.tokenizer, 'train', self.n_obs['train'], self.hparams)\n",
    "        return DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        validation_dataset = get_dataset(self.tokenizer, 'validation', self.n_obs['validation'], self.hparams)\n",
    "        return DataLoader(validation_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        test_dataset = get_dataset(self.tokenizer, 'test', self.n_obs['test'], self.hparams)\n",
    "        return DataLoader(test_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5efb9bd2-25d5-4bc2-a565-8e6e0124c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args_dict = {\n",
    "    'model_name_or_path': 't5-large',\n",
    "    'tokenizer_name_or_path': 't5-large',\n",
    "    'max_input_length': 512,\n",
    "    'max_output_length': 512,\n",
    "    'freeze_encoder': False,\n",
    "    'freeze_embeds': False,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.0,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_steps': 0,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'num_train_epochs': 3,\n",
    "    'n_train': 2000,  #training samples\n",
    "    'n_val': 400,     # validation samples\n",
    "    'n_test': 400,    #test samples\n",
    "    'gradient_accumulation_steps': 16,\n",
    "    'n_gpu': 1,\n",
    "    'early_stop_callback': False,\n",
    "    'fp_16': False,  \n",
    "    'opt_level': 'O1', \n",
    "    'max_grad_norm': 1.0,\n",
    "    'seed': 42,\n",
    "    #'total_steps': (n_train / train_batch_size / gradient_accumulation_steps) * num_train_epochs\n",
    "    'total_steps': 23\n",
    "}\n",
    "args = Namespace(**args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "841dab8e-f47f-4769-933b-f88d47493d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca765761-672a-4c13-ad7c-19c830d259d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=args.num_train_epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b48063a-2f6e-406d-ad7c-b4b7b8180496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/goodone/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                         | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379cdbc6c0a24244988d4d56a263c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                              | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13ace75c-f15f-4323-802a-b6bfe8af971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # set the model to evaluation mode\n",
    "\n",
    "# Function to generate summary\n",
    "def generate_summary(text, max_length=700):\n",
    "    # Tokenize the input text\n",
    "    inputs =  T5Tokenizer.from_pretrained('t5-small').encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.model.generate(inputs, max_length=max_length, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    return T5Tokenizer.from_pretrained('t5-small').decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69aee839-27e5-40e8-a289-c24816d796d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the patient was taken to the cardiac catheterization laboratory and underwent a cardiac catheterization, which revealed a left ventricular ejection fraction of 55% and a left main coronary artery occlusion of 90%. he underwent coronary artery bypass grafting times four with a left internal mammary artery graft to the left anterior descending artery, a saphenous vein graft to the left anterior descending artery, a saphenous vein graft\n"
     ]
    }
   ],
   "source": [
    "test_example = pd.read_csv('test_data.csv')\n",
    "input_text = test_example['medical_history'].iloc[12]\n",
    "summary = generate_summary(input_text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c74cfa18-5afa-4cbd-82cc-a69c9143b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 78-year-old gentleman\n",
      "who presented to the cardiac catheterization laboratory after\n",
      "being referred for approximately three episodes of chest pain\n",
      "while walking followed by a positive exercise tolerance test.\n"
     ]
    }
   ],
   "source": [
    "print(test_example['ground_truth_summary'].iloc[12])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
